1ï¸âƒ£ Cadrer le projet

Lister les types de questions Ã  gÃ©rer (programmes, admissions, cours, contactâ€¦)

Lister les sources : pages du site ESILV + docs internes (PDF, docs fournis)

2ï¸âƒ£ PrÃ©parer le web scraping

Lister les URL importantes du site ESILV Ã  scraper

Ã‰crire un script de scraping (requests + BeautifulSoup ou autre)

Extraire le texte utile de chaque page (sans menus, footers, cookies, etc.)

Sauvegarder le texte brut + mÃ©tadonnÃ©es (URL, titre, type de contenu)

3ï¸âƒ£ PrÃ©parer les documents pour le RAG

Charger les docs internes (PDF, etc.) et en extraire le texte

DÃ©couper tous les textes (site + docs internes) en â€œchunksâ€ de taille raisonnable

Associer des mÃ©tadonnÃ©es Ã  chaque chunk (source, thÃ¨me, URL, etc.)

Stocker le tout dans un format exploitable (JSON, CSV, ou direct vector store)

4ï¸âƒ£ Mettre en place les embeddings + base vectorielle

Choisir un modÃ¨le dâ€™embedding (local via Ollama ou API/cloud)

GÃ©nÃ©rer les embeddings de tous les chunks

Stocker les embeddings dans un vector store (FAISS, Chroma, etc.)

Ã‰crire une fonction : question utilisateur â†’ recherche des k chunks les plus proches

5ï¸âƒ£ CrÃ©er lâ€™agent RAG (FAQ ESILV)

Ã‰crire une fonction qui :

prend la question utilisateur

rÃ©cupÃ¨re les passages les plus pertinents via le vector store

envoie au LLM : question + contexte pour gÃ©nÃ©rer la rÃ©ponse

GÃ©rer la mise en forme de la rÃ©ponse (optionnel : citer les sources)

6ï¸âƒ£ CrÃ©er lâ€™agent â€œformulaire / contactâ€

DÃ©finir les infos Ã  collecter : nom, prÃ©nom, email, type de demande, niveau dâ€™Ã©tude, etc.

CrÃ©er une logique de dialogue guidÃ© (pose des questions si info manquante)

Sauvegarder les infos collectÃ©es (CSV, base SQLite, Google Sheet, etc.)

PrÃ©voir un format de â€œfiche contactâ€ pour lâ€™admin

7ï¸âƒ£ DÃ©finir la dÃ©tection dâ€™intentions

DÃ©finir des catÃ©gories : question_info, inscription/contact, autre

Ã‰crire une fonction ou un petit prompt LLM qui classe lâ€™intention dâ€™un message

Tester avec quelques exemples de phrases

8ï¸âƒ£ CrÃ©er lâ€™agent orchestrateur

En fonction de lâ€™intention dÃ©tectÃ©e :

si question_info â†’ appeler lâ€™agent RAG

si inscription/contact â†’ appeler lâ€™agent formulaire

si autre â†’ rÃ©ponse gÃ©nÃ©rique ou redirection

Encapsuler Ã§a dans une fonction centrale : handle_user_message(message, state)

9ï¸âƒ£ Construire lâ€™interface Streamlit

CrÃ©er une page principale â€œChatbot ESILVâ€

zone dâ€™affichage de la conversation

champ de saisie du message

Connecter Streamlit Ã  la fonction handle_user_message

GÃ©rer lâ€™historique de la conversation (session_state)

ğŸ”Ÿ Ajouter la partie admin dans Streamlit

Page â€œAdminâ€

afficher les contacts collectÃ©s (table)

option pour exporter les contacts (CSV)

Ã©ventuellement un bouton â€œRe-scraper le site / mettre Ã  jour la baseâ€

Page â€œDocumentsâ€

lister les sources du RAG (pages, PDF)

afficher quelques exemples de chunks

1ï¸âƒ£1ï¸âƒ£ IntÃ©grer Ollama ou Google AI

Option locale (Ollama) :

installer Ollama, tÃ©lÃ©charger le modÃ¨le

Ã©crire une fonction Python qui interroge le modÃ¨le local

Option GCP :

configurer un projet GCP

utiliser lâ€™API (Geminiâ€¦) pour le LLM et/ou les embeddings

Adapter le code pour pouvoir switcher de backend (local vs cloud)

1ï¸âƒ£2ï¸âƒ£ Tester et ajuster

Tester des scÃ©narios rÃ©els :

â€œComment intÃ©grer la majeure Data & AI ?â€

â€œJe veux laisser mon email pour Ãªtre recontactÃ©.â€

VÃ©rifier que :

le bon agent est appelÃ©

les rÃ©ponses RAG sont cohÃ©rentes

les contacts sont bien enregistrÃ©s

Ajuster les prompts, le dÃ©coupage des textes, les intentions si besoin

1ï¸âƒ£3ï¸âƒ£ PrÃ©parer la soutenance / rendu

Faire un schÃ©ma dâ€™architecture (scraping â†’ RAG â†’ agents â†’ Streamlit)

Documenter :

comment lancer le chatbot

oÃ¹ sont les donnÃ©es

comment ajouter des nouvelles pages / docs

comment voir les contacts
